# Сервис предсказания цен автомобилей
## Разведовательный анализ и обучение модели

Для работы с файлами установите вирутальное окружение и все необходимые пакеты:
```
python3.11 -m venv venv_p3.11_hometasks_ai25   

source ./venv_p3.11_hometasks_ai25/bin/activate

pip install -r requirements.txt

jupyter lab
```

1. Был проведен разведовательный анализ тренировочной и тестовой выборки.
    - Были обнаружены явные и не явные дубликаты. В тренировчной выборке от явных дубликатов избавились по средствам оставления первого входящего значения в выборку.

    - Были обнаружены пропуски, которые заполнили медианой.

    - Построили графики `pairplot` для визуального определения зависимостей между признаками, а также сравнения распределения признаков в тренировочной и тестовой выборке. При анализе было выявлено, что распределения в обоих выборках похожи, а также наблюдается нелинейная зависимость между некоторыми признаками.

    - Была посчитана коррелция Пирсона и Спирмена. Выявлена зависимость между следующими признаками:
          самая сильная зависимость наблюдается между `max_power` и `selling_price` по корреляции Пирсона,
          сильно коррелируют между собой `engine`, `max_power` и `torque` по корреляции Спирмена.

    - Построили матрицу корреляций из библиотеки `phik`. Обнаружили еще более ярковы выраженную зависимость между `max_power` и `selling_price`. Появилась сильная корреляция между `torque` и `max_torque_rpm`.

    - Дополнительно были построены графики распределения средней цены авто от категориальных факторов. Авто с меньшим количеством владельцев, на автомате, на дизиле и у дилера стоят дороже, чем в других категориях каждого признака.

    - По круговой диаграмме категориальных признаков был выявлен не критичный дисбаланс.

    - По графику боксплот видны выбросы в числовых признаках.

2. Обучили модель линейной регрессии только на вещественных признаках, получили качество `R2`=0.6. Реализовали метрику `adjusted R2`, получили значение 0.39.

3. Стандартизировали признаки и заново провели обучение. Метрика не поменялась `R2`=0.6. Самым значимым признаком в обучении оказался `max_power`.

4. Обучили Lasso регрессию на дефолтных параметрах, получили такой же результат метрики `R2`=0.6.

5. Добавили GridSearchCV к Lasso регрессии с сеткой параметров
   `lasso_param_grid = {
    'alpha': [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],
    'max_iter': [1000, 2000, 5000],
    'selection': ['cyclic', 'random']}`
    метрика `R2` стала хуже.

6. Обучили GridSearchCV с ElasticNet регрессией с параметрами
   `elastic_net_param_grid = {
    'alpha': [0.001, 0.01, 0.1, 1.0, 10.0],
    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],
    'max_iter': [1000, 2000, 5000]
    }`
   метрика `R2` стала еще хуже.

7. Написали класс L0LinearRegression и обучили с разным коэффициентом регуляризации. Эксперимент показал, что при увеличении `alpha` растет количество нулевых весов, но падает метрика `R2`. Была выбрана оптимальная медель с коэффициентом `alpha`=0.1, которая зануляет половину признаков, но при этом показывает метрику `R2`=0.596.

8. Добавлены категориальные признаки, которые были закодированы с помощью OneHotEncoder.

9. Написан pipeline с Ridge регрессией и подбором гиперпараметров с GridSearchCV по сетке
    `ridge_param_grid = {
    'model__alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}`
   метрика стала лучше `R2`=0.78.

10. Проведен feature engineering:
    - Возведение в квадрат `year`.
    - Умножение `engine` и `max_power`.
    - Взятие логарифма из `torque`.
    - Добавление флага `gas` на основе `fuel`.

    Также были не успешные попытки:
    - Возведение во всякие разные степени `km_driven`.
    - Возведение в логарифм `km_driven`.
    - Дробление `km_driven` на партиции и кодирование как категориальный признак.
    - Добавление флага `Dealer` на основе признака `seller_type`.

    Также помогло избавление от выбросов в тренировочной выборке в признаках `km_driven`, `max_power`, `max_torque_rpm`.

    В итоге был построен pipeline Ridge регрессией и подбором гиперпараметров с GridSearchCV по сетке
    `ridge_param_grid = {
    'preprocessor__num_pipeline__imputer__strategy': ['median', 'mean'],
    'model__alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}`

    Получили наилучшую метрику `R2`=0.93
    Модель сохранена в файл pikle `feature_engineering_ridge_grid.pkl`

11. Были посчитаны бизнес метрики:
    - долю прогнозов, отличающихся от реальных цен на эти авто не более чем на 10% `bus_metric`,
    - долю прогнозов, где модель предсказала цену более чем на 20% ниже реальной `loss_bus_metric`.

Первая метрика с усложнением и улучшением модели начинает расти (+ 11 процентных пунктов от baseline модели), что говорит об увеличении доли авто, где цена не сильно отличается от реальной. Вторая метрика начинает уменьшаться от первой модели до итоговой, что говорит о снижении убытков компании в связи с более точными прогнозами цен.

13. Результаты всех экспериметов сохранены в `results_df`. Наглядно видно как при добавлении признаков и усложнении моделей растет качество.


| Этап                      | R2       | MSE          | bus_metric | loss_business_metric |
|---------------------------|----------|--------------|------------|---------------------|
| base_line                 | 0.600012 | 2.299244e+11 | 0.243      | 0.266              |
| scaled_linear             | 0.600012 | 2.299244e+11 | 0.243      | 0.266              |
| scaled_lasso              | 0.600011 | 2.299252e+11 | 0.243      | 0.266              |
| scaled_lasso_grid         | 0.586456 | 2.377167e+11 | 0.241      | 0.256              |
| scaled_elastic_net_grid   | 0.576889 | 2.432163e+11 | 0.256      | 0.242              |
| scaled_L0LinearRegression   | 0.596115 | 2.321645e+11 | 0.248      | 0.261              |
| scaled+cat_ridge_grid     | 0.782716 | 1.249013e+11 | 0.303      | 0.218              |
| feature_engineering_ridge_grid | 0.927577 | 4.163092e+10 | 0.355     | 0.193         |

## Деплой модели через сервис Streamlit

Для запуска streamlit сервиса локально введите команду
```
streamlit run streamlit_app.py
```